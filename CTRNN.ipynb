{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done\n",
    "* Make a basic CTRNN cell work\n",
    "* Make work with 3 dimensional input\n",
    "\n",
    "## ToDo\n",
    "* Create a multi-layered version (MTRNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good inspiration if you get stuck: [A noobâ€™s guide to implementing RNN-LSTM using Tensorflow](http://monik.in/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow/)\n",
    "\n",
    "Different cell types: [documentation](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1234\n",
    "num_input_class = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(num_input_class, size=(size,)))\n",
    "    X = onehot(X, num_input_class)\n",
    "#     print('X, gen\\t', X.shape)\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3, 1] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8, 1] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length, num_input_class], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i, :] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1), :]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(num_epochs, batch_size, num_steps):\n",
    "    for i in range(num_epochs):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)\n",
    "\n",
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "\n",
    "def onehot(t, num_classes):\n",
    "    out = np.zeros((t.shape[0], num_classes))\n",
    "    for row, col in enumerate(t):\n",
    "        out[row, col] = 1\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "# batch_size = 200\n",
    "\n",
    "num_steps = 10 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size= 200\n",
    "num_epochs=5\n",
    "learning_rate = 0.01\n",
    "\n",
    "num_units = 32\n",
    "input_dim = 2\n",
    "output_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from CTRNN import CTRNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_network(model, num_epochs, batch_size=32, num_steps=200, verbose=True, save=False):\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    training_losses = []\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print('\\tBegin training loop')\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, batch_size, num_steps)):\n",
    "            print('epoch', idx)\n",
    "            training_loss = 0\n",
    "            steps = 0\n",
    "            state_tuple = model.zero_state_tuple(batch_size=batch_size)\n",
    "#             print('state_tuple', type(state_tuple[0]), state_tuple[0].get_shape(), \n",
    "#                   state_tuple[1][0].get_shape(), state_tuple[1][0].get_shape())\n",
    "            for X, Y in epoch:\n",
    "#                 print('X!\\t', X.shape)\n",
    "                steps += 1\n",
    "                feed_dict = {model.x:X, model.y:Y, model.init_tuple:state_tuple}\n",
    "                training_loss_, _, state_tuple = sess.run([\n",
    "                        model.total_loss, \n",
    "                        model.train_op,\n",
    "                        model.state_tuple\n",
    "                    ], \n",
    "                        feed_dict=feed_dict)\n",
    "                training_loss += training_loss_\n",
    "\n",
    "                if steps % 100 == 0 and steps > 0:\n",
    "                    if verbose:\n",
    "                        print('Average loss at step', steps,\n",
    "                             'for last 100 steps: ', training_loss/100.)\n",
    "                    training_losses.append(training_loss/100.)\n",
    "                    training_loss = 0                    \n",
    "#                     break\n",
    "#                 break\n",
    "    return training_losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import CTRNN\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# y = tf.placeholder(tf.int32, shape=[None, num_steps], name='outputPlaceholder')\n",
    "# x = tf.placeholder(tf.float32, shape=[None, num_steps, input_dim], name='inputPlaceholder')\n",
    "# # x = tf.placeholder(tf.int32, shape=[None, num_steps], name='inputPlaceholder')\n",
    "# init_c1 = tf.placeholder(tf.float32, shape=[None, num_units], name='initC')\n",
    "# init_c2 = tf.placeholder(tf.float32, shape=[None, num_units], name='initC')\n",
    "# init_u = tf.placeholder(tf.float32, shape=[None, num_units], name='initU')\n",
    "# init_tuple = (init_c1, (init_c2, init_u))\n",
    "\n",
    "print('Creating the model')\n",
    "# model = CTRNNModel(x=x, y=y, init_tuple=init_tuple, input_dim=input_dim, num_units=num_units, output_dim=output_dim, learning_rate=learning_rate)\n",
    "model = CTRNNModel(num_steps=num_steps, input_dim=input_dim, num_units=num_units, output_dim=output_dim, learning_rate=learning_rate)\n",
    "print('\\nTraining:')\n",
    "loss = train_network(model, num_epochs=num_epochs, batch_size=batch_size, num_steps=num_steps)\n",
    "\n",
    "\n",
    "print('Terminated!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('No learning:\\t', 0.66)\n",
    "print('3 dep learning:\\t', 0.52)\n",
    "print('8 dep learning:\\t', 0.45)\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
