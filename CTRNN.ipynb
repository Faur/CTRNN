{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done\n",
    "* Make a basic CTRNN cell work\n",
    "* Make work with 3 dimensional input\n",
    "* Make tau trainable\n",
    "* Create a multi-layered version (MTRNN)\n",
    "\n",
    "## ToDo\n",
    "* Ensure that wiring is okay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good inspiration if you get stuck: [A noobâ€™s guide to implementing RNN-LSTM using Tensorflow](http://monik.in/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow/)\n",
    "\n",
    "Different cell types: [documentation](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time, datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1234\n",
    "RANDOM_SEED = int(time.time())\n",
    "num_input_class = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(num_input_class, size=(size,)))\n",
    "    X = onehot(X, num_input_class)\n",
    "#     print('X, gen\\t', X.shape)\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3, 1] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8, 1] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length, num_input_class], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i, :] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1), :]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(num_epochs, batch_size, num_steps):\n",
    "    for i in range(num_epochs):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)\n",
    "\n",
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "\n",
    "def onehot(t, num_classes):\n",
    "    out = np.zeros((t.shape[0], num_classes))\n",
    "    for row, col in enumerate(t):\n",
    "        out[row, col] = 1\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "# batch_size = 200\n",
    "\n",
    "num_steps = 10 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_epochs = 20\n",
    "learning_rate = 0.01\n",
    "\n",
    "# num_unit = 6\n",
    "input_dim = 2\n",
    "output_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from CTRNN import CTRNNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "* [Statistics Tutorial](https://www.tensorflow.org/get_started/summaries_and_tensorboard)\n",
    "* [Graph Tutorial](https://www.tensorflow.org/get_started/graph_viz)\n",
    "* [TensorBoard README](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/tensorboard/README.md)\n",
    "* [tf.summary.FileWriter](https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_printer(obj, prefix):\n",
    "    try:\n",
    "        print(prefix, obj.shape)\n",
    "    except AttributeError:\n",
    "        print(prefix, type(obj))\n",
    "        for o in obj:\n",
    "            shape_printer(o, prefix + '\\t')\n",
    "\n",
    "def time_str():\n",
    "    return datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d-(%H-%M-%S)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_network(model, num_epochs, batch_size=32, num_steps=200, verbose=True, save=False):\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    training_losses = []\n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print('\\tBegin training loop')\n",
    "        steps = 0\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, batch_size, num_steps)):\n",
    "            print('epoch', idx)\n",
    "            training_loss = 0\n",
    "            state_tuple = model.zero_state_tuple(batch_size=batch_size)\n",
    "#             print('state_tuple', type(state_tuple[0]), state_tuple[0].get_shape(), \n",
    "#                   state_tuple[1][0].get_shape(), state_tuple[1][0].get_shape())\n",
    "            for X, Y in epoch:\n",
    "                steps += 1\n",
    "#                 print('Just before sess.run')\n",
    "#                 print('state_tuple', type(state_tuple))\n",
    "#                 shape_printer(state_tuple, 'tl')\n",
    "                feed_dict = {model.x:X, model.y:Y, model.init_tuple:state_tuple}\n",
    "                training_loss_, _, state_tuple, summary = sess.run([\n",
    "                        model.total_loss, \n",
    "                        model.train_op,\n",
    "                        model.state_tuple,\n",
    "                        model.TBsummaries\n",
    "                    ], \n",
    "                        feed_dict=feed_dict)\n",
    "#                 print('Just after sess.run')\n",
    "                training_loss += training_loss_\n",
    "                summary_writer.add_summary(summary, steps)\n",
    "\n",
    "                if steps % 100 == 0 and steps > 0:\n",
    "                    if verbose:\n",
    "                        print('Average loss at step', steps,\n",
    "                             'for last 100 steps: ', training_loss/100.)\n",
    "                        tau = sess.run(model.tau)\n",
    "                        print('tau', tau)\n",
    "                    training_losses.append(training_loss/100.)\n",
    "                    training_loss = 0                    \n",
    "#                     break\n",
    "#                 break\n",
    "    return training_losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import CTRNN\n",
    "logdir = 'logdir/' + time_str()\n",
    "# logdir = 'logdir/' + '3l-botCrap'\n",
    "print('logdir:', logdir)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "### WIRING TEST\n",
    "## Success criteria\n",
    "# 1) 3l-topCrap and 2l should perform equally well\n",
    "# 2) 3l-botCrap should perform very poorly \n",
    "## Results:\n",
    "# 1) Succss\n",
    "# 2) 3l-botCrap performed very poorly for a long time, but eventually (epoch 7) got almost as good results as the others.\n",
    "## Conclusion\n",
    "# The wiring is probably correct, but \n",
    "\n",
    "taus = [tf.Variable(5, name='tau', dtype=tf.float32, trainable=True), \n",
    "        tf.Variable(5, name='tau', dtype=tf.float32),\n",
    "        tf.Variable(50000, name='tau', dtype=tf.float32, trainable=False)]\n",
    "num_units = [8, 8, 8]\n",
    "\n",
    "# 3l-botCrap\n",
    "taus = [tf.Variable(50000, name='tau', dtype=tf.float32, trainable=False), \n",
    "        tf.Variable(5, name='tau', dtype=tf.float32),\n",
    "        tf.Variable(5, name='tau', dtype=tf.float32, trainable=True)]\n",
    "num_units = [8, 8, 8]\n",
    "\n",
    "# # 2l\n",
    "# taus = [tf.Variable(5, name='tau', dtype=tf.float32, trainable=True), \n",
    "#         tf.Variable(5, name='tau', dtype=tf.float32)]\n",
    "# num_units = [8, 8]\n",
    "\n",
    "# 3l\n",
    "taus = [tf.Variable(1, name='tau', dtype=tf.float32, trainable=True), \n",
    "        tf.Variable(2, name='tau', dtype=tf.float32),\n",
    "        tf.Variable(2, name='tau', dtype=tf.float32),\n",
    "        tf.Variable(2, name='tau', dtype=tf.float32, trainable=True)]\n",
    "num_units = [2,2,2,2] \n",
    "\n",
    "\n",
    "print('Creating the model\\n')\n",
    "model = CTRNNModel(num_units=num_units, tau=taus, num_steps=num_steps, input_dim=input_dim, output_dim=output_dim, learning_rate=learning_rate)\n",
    "print('\\nTraining:')\n",
    "loss = train_network(model, num_epochs=num_epochs, batch_size=batch_size, num_steps=num_steps)\n",
    "\n",
    "\n",
    "print('Terminated!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('No learning:\\t', 0.66)\n",
    "print('3 dep learning:\\t', 0.52)\n",
    "print('8 dep learning:\\t', 0.45)\n",
    "# plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
